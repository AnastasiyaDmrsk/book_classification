
# Clasificaci贸n de Libros por G茅nero

## Descripci贸n del Proyecto

### Motivaci贸n y Objetivos
El objetivo de este proyecto es desarrollar un modelo de clasificaci贸n de texto capaz de predecir el **g茅nero principal de un libro** (fantas铆a, misterio, romance, ciencia ficci贸n, etc.) a partir de su **descripci贸n**. Esta tarea tiene aplicaciones pr谩cticas en bibliotecas digitales, recomendaciones autom谩ticas y organizaci贸n de cat谩logos editoriales.

### Dataset Utilizado
Se utiliz贸 el dataset de Kaggle:  
 [Books Dataset - Kaggle](https://www.kaggle.com/datasets/abdallahwagih/books-dataset/data)  
Este dataset fue seleccionado por contener una menor proporci贸n de valores nulos y una buena variedad de g茅neros.

---

## Desarrollo del Trabajo

### Preprocesamiento
- Se eliminaron entradas con descripciones (`description`) o categor铆as (`categories`) nulas.
- Se extrajo la **categor铆a principal** de cada libro (`main_category`), usando el primer valor del campo `categories`.
- Se seleccionaron los **10 g茅neros m谩s frecuentes** para reducir la complejidad y balancear las clases.
- Se codificaron las etiquetas con `LabelEncoder`.

### Divisi贸n de Datos
- 80% para entrenamiento y 20% para prueba, usando `train_test_split`.

### Representaci贸n del Texto
Se probaron dos enfoques para representar las descripciones de los libros:

#### 1. **TF-IDF (Term Frequency - Inverse Document Frequency)**
- Se utiliz贸 `TfidfVectorizer` con los siguientes par谩metros:
  - `max_features=5000`
  - `stop_words="english"`

#### 2. **Embeddings con Transformers (Hugging Face)**
- Modelo usado: `DistilBERT` (`distilbert-base-uncased`)
- Se entren贸 un modelo de clasificaci贸n (`DistilBertForSequenceClassification`)
- Se utiliz贸 `Trainer` de Hugging Face para entrenamiento y evaluaci贸n.

### Modelos de Clasificaci贸n Probados
Con representaciones TF-IDF:
- Naive Bayes
- Regresi贸n Log铆stica
- Random Forest
- SVM (LinearSVC)

Con representaciones Transformers:
- DistilBERT fine-tuneado usando la sinopsis como entrada.

---

## Resultados

| Modelo                | Accuracy         | F1 Score (ponderado) |
|------------------------|------------------|----------------------|
| Naive Bayes           | 0.574            | TODO                 |
| Regresi贸n Log铆stica   | 0.650               | TODO                 |
| Random Forest         | 0.663               | TODO                 |
| SVM                   | 0.710               | TODO                     |
| **DistilBERT**        | TODO| TODO |

> *Los resultados concretos dependen del entrenamiento, pero en general DistilBERT mostr贸 un rendimiento significativamente superior en t茅rminos de F1 Score y generalizaci贸n.*

---

## Guardado del Modelo
Se guard贸 el modelo fine-tuneado y el tokenizer de Hugging Face con:

```python
model.save_pretrained("book_genre_classifier_model")
tokenizer.save_pretrained("book_genre_classifier_model")
```

Tambi茅n se guard贸 el `LabelEncoder` para decodificar las predicciones:
```python
joblib.dump(label_encoder, "label_encoder.pkl")
```

---

## Conclusiones

- Los modelos cl谩sicos con TF-IDF ofrecen resultados razonables, especialmente Logistic Regression y SVM.
- Sin embargo, los modelos basados en **Transformers (DistilBERT)** muestran una **mejora significativa** en la capacidad de capturar el significado sem谩ntico del texto.
- Este enfoque puede escalar f谩cilmente a m谩s categor铆as y otros idiomas.
- El modelo puede integrarse en sistemas de recomendaci贸n, motores de b煤squeda o bibliotecas virtuales para clasificar libros autom谩ticamente.
